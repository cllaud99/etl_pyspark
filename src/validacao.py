from pyspark.sql.functions import col, count, when, isnan
import logging

logger = logging.getLogger(__name__)


class Validacao:
    """
    Classe para valida√ß√£o e m√©tricas de qualidade de dados.
    Gera relat√≥rios de completude, duplicatas e estat√≠sticas.
    """

    def __init__(self, df):
        """
        Inicializa a classe com um DataFrame Spark.
        
        Par√¢metros:
            df (pyspark.sql.DataFrame): DataFrame a ser validado.
        """
        self.df = df

    def relatorio_qualidade(self, coluna_chave="PRONTUARIO"):
        """
        Gera relat√≥rio completo de qualidade dos dados.
        
        Par√¢metros:
            coluna_chave (str): Coluna a ser usada para verificar duplicatas.
        
        Retorna:
            dict: Dicion√°rio com todas as m√©tricas calculadas.
        """
        logger.info("üìä === INICIANDO RELAT√ìRIO DE QUALIDADE DOS DADOS ===")
        
        metricas = {}
        
        # 1. Completude
        logger.info("\nüîç === M√âTRICAS DE COMPLETUDE ===")
        metricas['completude'] = self._metricas_completude()
        
        # 2. Duplicatas
        logger.info("\nüîç === VERIFICA√á√ÉO DE DUPLICATAS ===")
        metricas['duplicatas'] = self._verificar_duplicatas(coluna_chave)
        
        # 3. Estat√≠sticas b√°sicas
        logger.info("\nüìà === ESTAT√çSTICAS DESCRITIVAS ===")
        self._estatisticas_basicas()
        
        logger.info("\n‚úÖ Relat√≥rio de qualidade conclu√≠do!")
        
        return metricas

    def _metricas_completude(self):
        """
        Calcula percentual de valores nulos por coluna.
        
        Retorna:
            dict: M√©tricas de completude por coluna.
        """
        total = self.df.count()
        metricas = {}
        
        for coluna in self.df.columns:
            # Verificar se a coluna √© num√©rica antes de aplicar isnan
            col_type = dict(self.df.dtypes)[coluna]
            
            if col_type in ('double', 'float', 'int', 'bigint', 'smallint', 'tinyint'):
                # Para colunas num√©ricas, verificar nulos e NaN
                nulos = self.df.filter(
                    col(coluna).isNull() | isnan(col(coluna))
                ).count()
            else:
                # Para colunas n√£o num√©ricas, verificar apenas nulos
                nulos = self.df.filter(col(coluna).isNull()).count()
            
            percentual_nulos = (nulos / total) * 100 if total > 0 else 0
            preenchidos = total - nulos
            percentual_preenchidos = 100 - percentual_nulos
            
            metricas[coluna] = {
                'total': total,
                'nulos': nulos,
                'preenchidos': preenchidos,
                'percentual_nulos': round(percentual_nulos, 2),
                'percentual_preenchidos': round(percentual_preenchidos, 2)
            }
            
            # Log formatado
            status = "‚úÖ" if percentual_nulos == 0 else "‚ö†Ô∏è" if percentual_nulos < 10 else "‚ùå"
            logger.info(
                f"  {status} {coluna:25} | "
                f"Preenchidos: {percentual_preenchidos:6.2f}% ({preenchidos:4}/{total:4}) | "
                f"Nulos: {percentual_nulos:5.2f}%"
            )
        
        return metricas

    def _verificar_duplicatas(self, coluna_chave):
        """
        Verifica registros duplicados com base em uma coluna chave.
        
        Par√¢metros:
            coluna_chave (str): Nome da coluna chave para verifica√ß√£o.
        
        Retorna:
            dict: M√©tricas sobre duplicatas.
        """
        total = self.df.count()
        distintos = self.df.select(coluna_chave).distinct().count()
        duplicados = total - distintos
        percentual_duplicados = (duplicados / total) * 100 if total > 0 else 0
        
        metricas = {
            'total': total,
            'unicos': distintos,
            'duplicados': duplicados,
            'percentual_duplicados': round(percentual_duplicados, 2)
        }
        
        status = "‚úÖ" if duplicados == 0 else "‚ö†Ô∏è"
        logger.info(f"  {status} Total de registros: {total}")
        logger.info(f"  {status} Registros √∫nicos: {distintos}")
        logger.info(f"  {status} Registros duplicados: {duplicados} ({percentual_duplicados:.2f}%)")
        
        return metricas

    def _estatisticas_basicas(self):
        """
        Mostra estat√≠sticas descritivas para colunas num√©ricas.
        """
        # Identificar colunas num√©ricas
        colunas_numericas = [
            field.name for field in self.df.schema.fields 
            if str(field.dataType) in ['DoubleType', 'IntegerType', 'FloatType', 'LongType']
        ]
        
        if colunas_numericas:
            logger.info(f"  Colunas num√©ricas analisadas: {', '.join(colunas_numericas)}")
            self.df.select(colunas_numericas).describe().show()
        else:
            logger.info("  ‚ö†Ô∏è Nenhuma coluna num√©rica encontrada para estat√≠sticas.")

    def validar_faixa_valores(self, coluna, min_val, max_val):
        """
        Valida se valores de uma coluna est√£o dentro de uma faixa esperada.
        
        Par√¢metros:
            coluna (str): Nome da coluna a validar.
            min_val (float): Valor m√≠nimo esperado.
            max_val (float): Valor m√°ximo esperado.
        
        Retorna:
            dict: M√©tricas de valida√ß√£o da faixa.
        """
        total = self.df.count()
        invalidos = self.df.filter(
            (col(coluna) < min_val) | (col(coluna) > max_val)
        ).count()
        validos = total - invalidos
        percentual_invalidos = (invalidos / total) * 100 if total > 0 else 0
        
        metricas = {
            'coluna': coluna,
            'faixa': f'{min_val} - {max_val}',
            'total': total,
            'validos': validos,
            'invalidos': invalidos,
            'percentual_invalidos': round(percentual_invalidos, 2)
        }
        
        status = "‚úÖ" if invalidos == 0 else "‚ö†Ô∏è"
        logger.info(
            f"  {status} {coluna}: {validos}/{total} valores dentro da faixa "
            f"[{min_val}, {max_val}] ({100 - percentual_invalidos:.2f}%)"
        )
        
        return metricas